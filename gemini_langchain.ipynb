{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-community\n",
    "\n",
    "!pip install langchain_google_genai\n",
    "\n",
    "!pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "PDF_PATH = \"Cap 07 Arrays.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(PDF_PATH)  # Load your PDF file\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "print(\"Total number of Chunks: \", len(docs))  # Check how many chunks we have\n",
    "for chunk in docs:\n",
    "    print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "api_key = \"AIzaSyCoxFsjIYKIz0jxIwlHYR5tI1by7LRvqw4\"\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set. Please set it as an environment variable.\")\n",
    "\n",
    "# Load the Gemini API key\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=api_key)\n",
    "\n",
    "# Test embedding a query\n",
    "vector = embeddings.embed_query(\"hello, world!\")\n",
    "print(len(vector))\n",
    "print(vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "PERSISTENT_DIRECTORY = \"chroma\"\n",
    "\n",
    "vectorstoredb = Chroma.from_documents(\n",
    "    documents=docs, embedding=embeddings, persist_directory=PERSISTENT_DIRECTORY\n",
    ")\n",
    "\n",
    "retriever = vectorstoredb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"como distinguir los objetivos especificos\")\n",
    "print(len(retrieved_docs))\n",
    "print(retrieved_docs[0].page_content)  # Print the first retrieved document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_passage(query, db, n_results):\n",
    "#   passage = db.query(query_texts=[query], n_results=n_results)['documents'][0]\n",
    "  return retriever.invoke(query)\n",
    "\n",
    "#Example usage\n",
    "relevant_text = get_relevant_passage(query=\"como distinguir los objetivos especificos\",db=None,n_results=3)\n",
    "\n",
    "relevant_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rag_prompt(query, relevant_passage):\n",
    "  # escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "  prompt = ('''You are a friendly and knowledgeable AI tutor that answers questions.  \n",
    "Your goal is to explain concepts clearly and thoroughly, breaking down any technical details into simple terms suitable for a non-technical audience.  \n",
    "Maintain a warm, conversational tone as if you are guiding a student step by step.  \n",
    "\n",
    "You must base your answer exclusively on the content from the passage and the examples included in it.  \n",
    "If the passage does not relate to the question, politely explain that the answer is not available in the provided material.  \n",
    "Respond **in Spanish**, and make sure your explanation is easy to follow.  \n",
    "The topic revolves around **C# programming**, so focus on simplifying and clarifying relevant concepts.\n",
    "\n",
    "At the end add a reference to the source, just the name of the document and pages of the passages.\n",
    "\n",
    "Do not add extra information.\n",
    "\n",
    "QUESTION: '{query}'  \n",
    "PASSAGE: '{relevant_passage}'  \n",
    "\n",
    "ANSWER: '''  \n",
    ").format(query=query, relevant_passage=relevant_passage)\n",
    "\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def generate_answer(prompt):\n",
    "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not gemini_api_key:\n",
    "        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "    \n",
    "    genai.configure(api_key=gemini_api_key)\n",
    "    model = genai.GenerativeModel('models/gemini-pro')\n",
    "    \n",
    "    # Pass temperature in a dictionary\n",
    "    generation_config = {\"temperature\": 0.3}\n",
    "    response = model.generate_content(contents=prompt, generation_config=generation_config)\n",
    "    \n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_2(db, query):\n",
    "    #retrieve top 3 relevant text chunks\n",
    "    relevant_text = get_relevant_passage(query,db,n_results=3)\n",
    "    prompt = make_rag_prompt(query, relevant_text) # joining the relevant chunks to create a single passage\n",
    "    answer = generate_answer(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = generate_answer_2(None, \"qu√© es un array\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
